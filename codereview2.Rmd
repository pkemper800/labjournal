---
title: "codereview2"
author: "Paige Kemper"
date: "2025-10-02"
output: html_document
---

VISUALIZING NETWORK 

# Goal: Visualize network of collaborations for RU Sociology professors

## Step 0: Load packages
```{r}
fpackage.check <- function(packages) {
    lapply(packages, FUN = function(x) {
        if (!require(x, character.only = TRUE)) {
            install.packages(x, dependencies = TRUE)
            library(x, character.only = TRUE)
        }
    })
}

fsave <- function(x, file = NULL, location = "./data/processed/") {
    ifelse(!dir.exists("data"), dir.create("data"), FALSE)
    ifelse(!dir.exists("data/processed"), dir.create("data/processed"), FALSE)
    if (is.null(file))
        file = deparse(substitute(x))
    datename <- substr(gsub("[:-]", "", Sys.time()), 1, 8)
    totalname <- paste(location, file, "_", datename, ".rda", sep = "")
    save(x, file = totalname)  #need to fix if file is reloaded as input name, not as x. 
}

fload <- function(filename) {
    load(filename)
    get(ls()[ls() != "filename"])
}

fshowdf <- function(x, ...) {
    knitr::kable(x, digits = 2, "html", ...) %>%
        kableExtra::kable_styling(bootstrap_options = c("striped", "hover")) %>%
        kableExtra::scroll_box(width = "100%", height = "300px")
}

```


```{r}
packages <- c("tidyverse", "scholar", "openalexR", "rvest", "jsonlite")
packages <- c("devtools", "igraph")

fpackage.check(packages)
```


## STEP 1: Load data
```{r}
library(readxl)
library(selenider)
library(rvest)
library(tidyverse)
library(netstat)
library(pingr)
library(jsonlite)
library(stringr)
library(openalexR)

# My manual data set, including manual review of professor experience abroad
ru_soc_profs <- read_excel("C:/Github/labjournal/ru_soc_profs.xlsx")
ru_soc_profs

# from tutorial
socprofs2022 <- read_excel("C:/Github/labjournal/2022scholarid_jt.xlsx")
socprofs2024 <- read_excel("C:/Github/labjournal/2024scholarid_jt.xlsx")
#now have list of scholars for all dutch universities 

scholars <- fload("C:/Github/labjournal/scholars_20240924.rda")
```


## STEP 2: Use with fcolnet
Have the option to loosen terms for university (RU -> Any dutch university)
```{r}
fcolnet <- function(data = scholars, university = "RU", discipline = "sociology", waves = list(c(2015,
    2018), c(2019, 2023)), type = c("first")) {

    # step 1 - cleaning data and isolating variables of interests
    demographics <- do.call(rbind.data.frame, data$demographics)
    demographics <- demographics %>%
        mutate(Universiteit1.22 = replace(Universiteit1.22, is.na(Universiteit1.22), ""), Universiteit2.22 = replace(Universiteit2.22,
            is.na(Universiteit2.22), ""), Universiteit1.24 = replace(Universiteit1.24, is.na(Universiteit1.24),
            ""), Universiteit2.24 = replace(Universiteit2.24, is.na(Universiteit2.24), ""), discipline.22 = replace(discipline.22,
            is.na(discipline.22), ""), discipline.24 = replace(discipline.24, is.na(discipline.24), ""))

    sample <- which((demographics$Universiteit1.22 %in% university | demographics$Universiteit2.22 %in%
        university | demographics$Universiteit1.24 %in% university | demographics$Universiteit2.24 %in%
        university) & (demographics$discipline.22 %in% discipline | demographics$discipline.24 %in% discipline))

    demographics_soc <- demographics[sample, ]
    scholars_sel <- lapply(scholars, "[", sample)

    # step 2 - compiling ids 
    ids <- demographics_soc$au_id
    nwaves <- length(waves)
    nets <- array(0, dim = c(nwaves, length(ids), length(ids)), dimnames = list(wave = 1:nwaves, ids,
        ids))
    dimnames(nets)

    # step 3 - look at selected scholars publications, compile df of all scholars' works (and deleting repeats)
    df_works <- tibble(works_id = unlist(lapply(scholars_sel$work, function(l) l$id)), works_author = unlist(lapply(scholars_sel$work,
        function(l) l$author), recursive = FALSE), works_year = unlist(lapply(scholars_sel$work, function(l) l$publication_year),
        recursive = FALSE))

    df_works <- df_works[!duplicated(df_works), ]

    # step 4 - for each work, look at the year, and the ego/alters involved, and if the publication has at least 1 ego and alter, make df ('nets') that compiles list of alters and egos (?)
    if (type == "first") {
        for (j in 1:nwaves) {
            df_works_w <- df_works[df_works$works_year >= waves[[j]][1] & df_works$works_year <= waves[[j]][2],
                ]
            for (i in 1:nrow(df_works_w)) {
                ego <- df_works_w$works_author[i][[1]]$au_id[1]
                alters <- df_works_w$works_author[i][[1]]$au_id[-1]
                if (sum(ids %in% ego) > 0 & sum(ids %in% alters) > 0) {
                  nets[j, which(ids %in% ego), which(ids %in% alters)] <- 1
                }
            }
        }
    }

    if (type == "last") {
        for (j in 1:nwaves) {
            df_works_w <- df_works[df_works$works_year >= waves[[j]][1] & df_works$works_year <= waves[[j]][2],
                ]
            for (i in 1:nrow(df_works_w)) {
                ego <- rev(df_works_w$works_author[i][[1]]$au_id)[1]
                alters <- rev(df_works_w$works_author[i][[1]]$au_id)[-1]
                if (sum(ids %in% ego) > 0 & sum(ids %in% alters) > 0) {
                  nets[j, which(ids %in% ego), which(ids %in% alters)] <- 1
                }
            }
        }
    }

    if (type == "all") {
        for (j in 1:nwaves) {
            df_works_w <- df_works[df_works$works_year >= waves[[j]][1] & df_works$works_year <= waves[[j]][2],
                ]
            for (i in 1:nrow(df_works_w)) {
                egos <- df_works_w$works_author[i][[1]]$au_id
                if (sum(ids %in% egos) > 0) {
                  nets[j, which(ids %in% egos), which(ids %in% egos)] <- 1
                }
            }
        }
    }
    output <- list()
    output$data <- scholars_sel
    output$nets <- nets
    return(output)
}
```


Test fcolnet - make adjacency matrix with first wave of data
```{r}
#save the output of your function
test <- fcolnet(data = scholars, 
                university = "RU", 
                discipline = "sociology", 
                waves = list(c(2015, 2018), c(2019, 2023)), 
                type = c("first"))



# make adjacency matrix with first wave of data
test_w1 <- igraph::graph_from_adjacency_matrix(
  test$nets[1,,], #for this example I take the first wave of data. (thus I select the array of networks and take the first matrix)
  mode = c("directed"),
  weighted = NULL,
  diag = FALSE,
  add.colnames = NULL,
  add.rownames = NULL
)


plot(test_w1,
  vertex.label = NA,
  edge.width = 0.2,
  edge.arrow.size =0.2)

```

# Step 3: Incorporate Ego level characteristics

```{r}
test <- fcolnet(data = scholars, 
                university = c("RU", "UvT"), 
                discipline = c("sociology", "political science"), 
                waves = list(c(2015, 2018), c(2019, 2023)), 
                type = c("all"))

test_w2 <- igraph::graph_from_adjacency_matrix(
  test$nets[2,,], #now, I take the second wave
  mode = c("directed"),
  weighted = NULL,
  diag = FALSE,
  add.colnames = NULL
)

#Let us find ego characteristics. 
#first fish out the data
df <- test$data

#same complicated structure as 'scholars' thus first make a dataframe from the list in which all info was saved. 
df_ego <- do.call(rbind.data.frame, df$demographics)

#DO NOT MESS UP THE ORDER! THUS IF YOU JOIN THIS DATA WITH YOUR OWN DATA CHECK THAT ORDER REMAINED THE SAME!! 

plot(test_w2,
  vertex.color = ifelse(df_ego$discipline.24 == "sociology", "red", "blue"), #now, I can use actor attributes for plotting. 
  vertex.label = NA,
  edge.width = 0.2,
  edge.arrow.size =0.2)
```

# Step 4: Apply igraph 
Learnings from class last week. 

## Recap: 
-   data <- comes from 'scholars'; split into subsections/elements. inspecting 'demographic' element. 
-   sample <- looking at change in demographics between time 1 and time 2 in 2 different universities. 

We have already made adjacency matrix -- here is entire code: 
```{r}
# for reference from lab 4: 
# GMAT: the adjacency matrix for g  -->  now that is 
# g: the graph/plot  -->  now that is test_w1 and test_w2

# g <- make_graph("Zachary")
# plot(g)

# gmat <- as_adjacency_matrix(g, type = "both", sparse = FALSE)
# gmat

# number of nodes
# vcount(g)
# number of edges
# ecount(g) 


# make adjacency matrix with first wave of data
test_w1 <- igraph::graph_from_adjacency_matrix(
  test$nets[1,,], #for this example I take the first wave of data. (thus I select the array of networks and take the first matrix)
  mode = c("directed"),
  weighted = NULL,
  diag = FALSE,
  add.colnames = NULL,
  add.rownames = NULL
)
plot(test_w1,
  vertex.label = NA,
  edge.width = 0.2,
  edge.arrow.size =0.2)


# make adjacency matrix with second wave 
test_w2 <- igraph::graph_from_adjacency_matrix(
  test$nets[2,,], #now, I take the second wave
  mode = c("directed"),
  weighted = NULL,
  diag = FALSE,
  add.colnames = NULL
)

# find ego characteristics. 
# first fish out the data
df <- test$data

#same complicated structure as 'scholars' thus first make a dataframe from the list in which all info was saved. 
df_ego <- do.call(rbind.data.frame, df$demographics)

plot(test_w2,
  vertex.color = ifelse(df_ego$discipline.24 == "sociology", "red", "blue"), #now, I can use actor attributes for plotting. 
  vertex.label = NA,
  edge.width = 0.2,
  edge.arrow.size =0.2)


plot(test_w1)
plot(test_w2)
```



## NOW - LOOK AT DESCRIPTIVE STATISTICS
```{r}
#SIZE
# number of nodes
vcount(test_w1)
vcount(test_w2)

# number of edges
ecount(test_w1)
ecount(test_w2)


#DEGREE
# looking at clustering and spread
igraph::degree(test_w1)
igraph::degree(test_w2)

hist(table(degree(test_w1)), xlab='indegree', main= 'Histogram of indegree') 
# every number is the degree level of each actor -- and see it is heavily skewed to the left

hist(table(degree(test_w2)), xlab='indegree', main= 'Histogram of indegree') # every number is the degree level of each actor -- and see it is heavily left skewed too  


#TRANSITIVITY -- all of these return "NAN" -- check?
# directed: be aware that directed graphs are considered as undirected. CHECK IF TEST_W1 AND 2 ARE DIRECTED OR UNDIRECTED.
igraph::transitivity(test_w1, type = c("localundirected"), isolates = c("NaN", "zero")) #differences pop out less 
igraph::transitivity(test_w2, type = c("localundirected"), isolates = c("NaN", "zero")) #differences pop out less 

igraph::transitivity(test_w1, type = c("localundirected"), isolates = c("NaN", "zero")) #differences pop out less 


#BETWEENNESS
# directed: be aware that directed graphs are considered as undirected. CHECK IF TEST_W1 AND 2 ARE DIRECTED OR UNDIRECTED.
igraph::transitivity(test_w1, type = c("localundirected"), isolates = c("NaN", "zero"))
igraph::transitivity(test_w2, type = c("localundirected"), isolates = c("NaN", "zero"))


```



## Next, moving from local to global transitivity 
-   Look at triads for more global transitivity. Note: Global = number of observed over possible - can identify all transitive triads and all possible triads 
-   Reviewing dyads - then triads. Since it is undirected, it is less difficult to calculate. 
-   Now, looking at triad census vs triad allegation

```{r}

# plot: igraph - XX <- make_graph(y) <- test$nets[1,,] ??
# adj mat: XX <- as_adj_matrix((plot), type = "both", sparse = FALSE) -- adj mat = test_w1 =  test$nets[1,,]


igraph::dyad.census(test_w1) #with plot -- works 
igraph::dyad.census(test_w2) #with plot -- works


igraph::triad.census(test_w1) #with plot -- works
igraph::triad.census(test_w2) #with plot -- works
# I will use sna because it shows the names of the triads as well.




install.packages("sna")
library(sna)

# Wave 1
sna::triad.census(test$nets[1,,]) #with adj matrix of test_w1 -- triad.census of (test_w1) doesn't work. 
unloadNamespace("sna")  #detach this package again to avoid interference with other igraph functions 

igraph::transitivity(test_w1, type = "global") #with plot
# sna::gtrans(test_w1) #triad census a different way, but this is with plot - need with adj mat:
sna::gtrans(test$nets[1,,]) #with adj matrix


triad_w1 <- data.frame(sna::triad.census(test$nets[1,,])) #save as df, #with adj matrix

transitivity_w1 <- (3 * triad_w1$X300)/(triad_w1$X201 + 3 * triad_w1$X300) #X300 is variable for transitive triad (the fully closed triad)
# we multiply by 3 because there are 3 possible transitive triads
transitivity_w1





# Wave 2
sna::triad.census(test$nets[2,,])
unloadNamespace("sna")  #I will detach this package again, otherwise it will interfere with all kind of functions from igraph, and my students will hate me for that.


igraph::transitivity(test_w2, type = "global")
sna::gtrans(test$nets[2,,]) #triad census a different way 

triad_w2 <- data.frame(sna::triad.census(test$nets[2,,])) #save as df

transitivity_w2 <- (3 * triad_w2$X300)/(triad_w2$X201 + 3 * triad_w2$X300) #X300 is variable for transitive triad (the fully closed triad)
# we multiply by 3 because there are 3 possible transitive triads
transitivity_w2

```



## 


Network visualisation: Let’s make size proportional to betweenness score
``` {r}
# changing V of Wave1
V(test_w1)$size = betweenness(test_w1, normalized = T, directed = FALSE) * 60 + 10  #after some trial and error


 ## multiplication - changing 60 changes the difference in size,, adding 10 makes the smallest visible
plot(test_w1, mode = "undirected")


# igraph, want no overlap: igraph plotting no overlap -- a lot of layout functions -- want to hold printing device constant, and then reduce overlap...the idea is to push least central egos out 

set.seed(2345)
l <- layout_with_mds(test_w1)  #https://igraph.org/r/doc/layout_with_mds.html
plot(test_w1, layout = l)
# story in second plot: 3 clusters, around 1, around 34 - and in between (which wasn't as clear before)


```


## 
```{r}

```



## 
```{r}

```










# Webscraping manual
## load data
```{r}
#FROM WEBSCRAPING MANUAL/TUTORIAL
socprofs2022$Universiteit1.22[socprofs2022$Naam == "Duygu Uysal Dincol"] <- "Koc University"
socprofs2022$Universiteit2.22[socprofs2022$Naam == "Duygu Uysal Dincol"] <- "UvA"

# correct the type
socprofs2022 <- socprofs2022 %>%
    mutate(across(c(Universiteit1.22, Universiteit2.22, Universiteit1.24, Universiteit2.24), ~case_when(.x ==
        "Uvt" ~ "UvT", .x == "UU?" ~ "UU", .x == "Leiden uni" ~ "Leiden", .x == "UvA?" ~ "UvA", .x ==
        "Uva" ~ "UvA", .x == "UU?" ~ "UU", .x == "Tilburg" ~ "UvT", is.na(.x) ~ "", .default = as.character(.x))))
fshowdf(socprofs2022)
```

## get institutions
```{r}
#FROM WEBSCRAPING MANUAL - GET INSTITUTIONS
instituties <- na.omit(unique(c(df_scholars$Universiteit1.22, df_scholars$Universiteit2.22, df_scholars$Universiteit1.24,
    df_scholars$Universiteit2.24)))
df_instituties <- data.frame(instituties)
fshowdf(instituties)


## INSTITUTIONS ID FROM WEBSRAPING TUTORIAL
options(openalexR.mailto = "paige.kemper@ru.nl") 


# Jochem's function so it is easier to use.
f_inst <- function(x) {
    # I am only interested in institution id and if I find multiple I only take the first one.
    oa_fetch(entity = "institutions", search = x)$id[1]
}

df_instituties$inst.id[df_instituties$instituties == "UU" | df_instituties$instituties == "UU?"] <- f_inst("Utrecht University")
df_instituties$inst.id[df_instituties$instituties == "Leiden" | df_instituties$instituties == "Leiden uni"] <- f_inst("Leiden University")
df_instituties$inst.id[df_instituties$instituties == "RU"] <- f_inst("Radboud University Nijmegen")
df_instituties$inst.id[df_instituties$instituties == "RUG"] <- f_inst("Rijksuniversiteit Groningen")
df_instituties$inst.id[df_instituties$instituties == "UvA" | df_instituties$instituties == "Uva" | df_instituties$instituties ==
    "UvA?"] <- f_inst("Universiteit van Amsterdam")
df_instituties$inst.id[df_instituties$instituties == "Universita degli studi di Milano"] <- f_inst("University of Milan")
df_instituties$inst.id[df_instituties$instituties == "VU"] <- f_inst("Vrije Universiteit Amsterdam")
df_instituties$inst.id[df_instituties$instituties == "VU"] <- f_inst("Vrije Universiteit Amsterdam")
df_instituties$inst.id[df_instituties$instituties == "EUR"] <- f_inst("Erasmus Universiteit Rotterdam")
df_instituties$inst.id[df_instituties$instituties == "UvT" | df_instituties$instituties == "Uvt" | df_instituties$instituties ==
    "Tilburg"] <- f_inst("Universiteit van Tilburg")
df_instituties$inst.id[df_instituties$instituties == "TU Delft"] <- f_inst("Technische Universiteit Delft")
df_instituties$inst.id[df_instituties$instituties == "TU Delft"] <- f_inst("Technische Universiteit Delft")
df_instituties$inst.id[df_instituties$instituties == "WUR"] <- f_inst("Wageningen University & Research")
# have to make complete


# SCHOLARS ID FROM WEBSCRAPING
df_scholars_list <- list()  #object where to save all author info

for (i in 1:nrow(df_scholars)) {
    naam <- df_scholars$Naam[i]  #retrieve name of scholar of interest

    # retrieve the affiliations/universities of this scholar
    universities <- unique(na.omit(c(df_scholars$Universiteit1.22[i], df_scholars$Universiteit2.22[i],
        df_scholars$Universiteit1.24[i], df_scholars$Universiteit2.24[i])))
    
    inst.ids <- na.omit(df_instituties$inst.id[df_instituties$instituties %in% universities])

    # search for the id(s) of this name filtering on all possible affiliations
    naam_list <- list()
    if (length(inst.ids) > 0) {
        # just to jump over scholars without affiliation (some external phds)
        for (j in 1:length(inst.ids)) {
            naam_list[[j]] <- oa_fetch(entity = "author", search = naam, affiliations.institution.id = inst.ids[j])
        }
        naam_list <- do.call(rbind.data.frame, naam_list)  #put everything in a dataframe
        naam_list <- naam_list[!duplicated(naam_list), ]  #remove duplicates

        # and save
        df_scholars_list[[i]] <- naam_list
    }
}
fsave(df_scholars_list, file = "df_scholars_list")


# THEN DF WITH ID AND FIRST ID
df_scholars$no_oa_id <- as.numeric(sapply(df_scholars_list, length) == 0)
df_scholars$au_id <- sapply(df_scholars_list, function(l) {
    if (is.null(l$id[1])) {
        NA
    } else {
        l$id[1]
    }
})
fshowdf(df_scholars)


# MAKE LIST OF WORKS FROM WEBSCRAPING TUTORIAL
works <- list()
nrow(df_scholars)
for (i in 1:nrow(df_scholars)) {
    if (df_scholars$no_oa_id[i] == 0) {
        id <- df_scholars_list[[i]]$id
        works[[i]] <- oa_fetch(entity = "works", author.id = id)
    }
}

# note that for quite some works we have a truncated author list. perhaps best to loop again ove
# all papers to find all authors.  apply(c('W2097078822', 'W1680837216'), \(x) oa_fetch(identifier
# = x))

# also note that there are many duplicates in the publications because i query for each author
# separately.
fsave(works, "works")

df_works <- fload("./data/processed/works_20240918.rda") # SAVE IT!!
```


## COMBINE AND CLEAN DATA - 1.9.1
```{r}
no_id <- which(df_scholars$no_oa_id == 1)
df_scholars_sel <- df_scholars[-no_id, ]
df_scholars_list_sel <- df_scholars_list[-no_id]
df_works_sel <- df_works[-no_id]

duplicates <- which(duplicated(df_scholars_sel$au_id) == 1)
df_scholars_sel <- df_scholars_sel[-duplicates, ]
df_scholars_list_sel <- df_scholars_list_sel[-duplicates]
df_works_sel <- df_works_sel[-duplicates]
demographics <- split(df_scholars_sel, row(df_scholars_sel)[, 1])

scholars <- list(demographics = demographics, scholars_oa = df_scholars_list_sel, works = df_works_sel)

scholars$demographics[[1]]$Naam
scholars$scholars_oa[[1]]$display_name
scholars$demographics[[1]]$Naam %in% scholars$works[[1]]$author[[1]]$au_display_name

scholars$demographics[[675]]$Naam
scholars$scholars_oa[[675]]$display_name
scholars$demographics[[675]]$Naam %in% scholars$works[[675]]$author[[1]]$au_display_name

# matching seems in order.
fsave(scholars, "scholars")

```


# Part 2 Nomination Networks
```{r}
rm(list = ls())


fpackage.check <- function(packages) {
    lapply(packages, FUN = function(x) {
        if (!require(x, character.only = TRUE)) {
            install.packages(x, dependencies = TRUE)
            library(x, character.only = TRUE)
        }
    })
}

fsave <- function(x, file = NULL, location = "./data/processed/") {
    ifelse(!dir.exists("data"), dir.create("data"), FALSE)
    ifelse(!dir.exists("data/processed"), dir.create("data/processed"), FALSE)
    if (is.null(file))
        file = deparse(substitute(x))
    datename <- substr(gsub("[:-]", "", Sys.time()), 1, 8)
    totalname <- paste(location, file, "_", datename, ".rda", sep = "")
    save(x, file = totalname)  #need to fix if file is reloaded as input name, not as x. 
}

fload <- function(filename) {
    load(filename)
    get(ls()[ls() != "filename"])
}

fshowdf <- function(x, ...) {
    knitr::kable(x, digits = 2, "html", ...) %>%
        kableExtra::kable_styling(bootstrap_options = c("striped", "hover")) %>%
        kableExtra::scroll_box(width = "100%", height = "300px")
}

packages <- c("tidyverse", "scholar", "openalexR", "rvest", "jsonlite")
fpackage.check(packages)
```


```{r}

```


```{r}

```

```{r}

```


```{r}

```

